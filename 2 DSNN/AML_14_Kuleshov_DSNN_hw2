{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"AML_14_Kuleshov_DSNN_hw2","provenance":[{"file_id":"1y2vX9lOI1KaMyOJbGegKs5QwVrkBRso5","timestamp":1620903308145},{"file_id":"https://github.com/waytobehigh/nlp_course/blob/master/week05_structured/rnn_tagger.ipynb","timestamp":1617022812789}],"collapsed_sections":["RhiWdaH_5lWK"],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7u8fiyzYd00O"},"source":["**AML-14. Кулешов Иван.**\n","\n","Домашнее задание по теме \"Введение в рекуррентные НС\""]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"l4VAzKlG8aHj"},"source":["## Neural Part Of Speech Tagging\n","\n","We're now going to solve the same problem of POS tagging with neural networks.\n","<img src=https://i.stack.imgur.com/6pdIT.png width=320>\n","\n","From deep learning perspective, this is a task of predicting a sequence of outputs aligned to a sequence of inputs. There are several problems that match this formulation:\n","* Part Of Speech Tagging -  an auxuliary task for many NLP problems\n","* Named Entity Recognition - for chat bots and web crawlers\n","* Protein structure prediction - for bioinformatics"]},{"cell_type":"code","metadata":{"id":"wnu9D3YZoH2e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621104290389,"user_tz":-420,"elapsed":5546,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"149bb40b-31cd-4da8-b1be-9237d92dcb20"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf"],"execution_count":8,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"yxFUBtb88aHq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621104300347,"user_tz":-420,"elapsed":6515,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"4df9ac8d-80d5-4fc4-f20b-56064b20f67b"},"source":["import nltk\n","import sys\n","import numpy as np\n","\n","nltk.download('brown')\n","nltk.download('universal_tagset')\n","data = nltk.corpus.brown.tagged_sents(tagset='universal')\n","all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n","\n","data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Package universal_tagset is already up-to-date!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  # Remove the CWD from sys.path while we load stuff.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Bq_OXuD38aHs","executionInfo":{"status":"ok","timestamp":1621104307448,"user_tz":-420,"elapsed":938,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["from sklearn.model_selection import train_test_split\n","train_data, test_data = train_test_split(data,test_size=0.25,random_state=42)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"sAlXrDmU8aHs","colab":{"base_uri":"https://localhost:8080/","height":155},"executionInfo":{"status":"ok","timestamp":1621104311441,"user_tz":-420,"elapsed":944,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"b2639895-b655-41d7-dfa2-90c54030d0e4"},"source":["from IPython.display import HTML, display\n","def draw(sentence):\n","    words,tags = zip(*sentence)\n","    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n","                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n","                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n","    \n","    \n","draw(data[11])\n","draw(data[10])\n","draw(data[7])"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"LAViiL2C8aHt"},"source":["### Building vocabularies\n","\n","Just like before, we have to build a mapping from tokens to integer ids. This time around, our model operates on a word level, processing one word per RNN step. This means we'll have to deal with far larger vocabulary.\n","\n","Luckily for us, we only receive those words as input i.e. we don't have to predict them. This means we can have a large vocabulary for free by using word embeddings."]},{"cell_type":"markdown","metadata":{"id":"V6jx-XLXntuQ"},"source":["### Создание словарей\n","\n","Как и раньше, нам нужно построить сопоставление токенов с целочисленными идентификаторами. На этот раз наша модель работает на уровне слов, обрабатывая одно слово за шаг RNN. Это означает, что нам придется иметь дело с гораздо большим словарным запасом.\n","\n","К счастью для нас, мы получаем только эти слова в качестве входных данных, т.е. нам не нужно их предсказывать. Это означает, что мы можем бесплатно иметь большой словарный запас, используя вложения слов."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"ZXK_k-mo8aHt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621104317788,"user_tz":-420,"elapsed":1542,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"0db81416-01aa-4c1f-daec-9576610ddede"},"source":["from collections import Counter\n","word_counts = Counter()\n","for sentence in data:\n","    words,tags = zip(*sentence)\n","    word_counts.update(words)\n","\n","all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n","\n","#let's measure what fraction of data words are in the dictionary\n","print(\"Coverage = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Coverage = 0.92876\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"T0hee8L88aHt","executionInfo":{"status":"ok","timestamp":1621104321826,"user_tz":-420,"elapsed":942,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["from collections import defaultdict\n","word_to_id = defaultdict(lambda:1, { word: i for i, word in enumerate(all_words) })\n","tag_to_id = { tag: i for i, tag in enumerate(all_tags)}"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RCmGbwpP8aHu"},"source":["convert words and tags into fixed-size matrix"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"X7kx6jWn8aHu","executionInfo":{"status":"ok","timestamp":1621104325148,"user_tz":-420,"elapsed":930,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n","    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n","    \n","    max_len = max_len or max(map(len,lines))\n","    matrix = np.empty([len(lines), max_len],dtype)\n","    matrix.fill(pad)\n","\n","    for i in range(len(lines)):\n","        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n","        matrix[i,:len(line_ix)] = line_ix\n","\n","    return matrix.T if time_major else matrix\n","\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"BCaE-i5u8aHu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621104328311,"user_tz":-420,"elapsed":1019,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"56ae2fc2-92db-4e6a-8329-97435b961464"},"source":["batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n","\n","print(\"Word ids:\")\n","print(to_matrix(batch_words, word_to_id))\n","print(\"Tag ids:\")\n","print(to_matrix(batch_tags, tag_to_id))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Word ids:\n","[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n","     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n","     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0]\n"," [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n","   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n","     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n","    12   10    2  861 5240   12    8 8936  121    1    4]\n"," [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n","     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0]]\n","Tag ids:\n","[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n","   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0]\n"," [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n","   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n","   6  3  2 13  7]\n"," [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"_oK_i5Xa8aHv"},"source":["### Build model\n","\n","Unlike our previous lab, this time we'll focus on a high-level keras interface to recurrent neural networks. It is as simple as you can get with RNN, allbeit somewhat constraining for complex tasks like seq2seq.\n","\n","By default, all keras RNNs apply to a whole sequence of inputs and produce a sequence of hidden states `(return_sequences=True` or just the last hidden state `(return_sequences=False)`. All the recurrence is happening under the hood.\n","\n","At the top of our model we need to apply a Dense layer to each time-step independently. As of now, by default keras.layers.Dense would apply once to all time-steps concatenated. We use __keras.layers.TimeDistributed__ to modify Dense layer so that it would apply across both batch and time axes."]},{"cell_type":"markdown","metadata":{"id":"hvAazwo1wcjd"},"source":["### Построить модель\n","\n","В отличие от нашей предыдущей лабораторной работы, на этот раз мы сосредоточимся на высокоуровневом интерфейсе keras для повторяющихся нейронных сетей. Это настолько просто, насколько вы можете получить с RNN, хотя и несколько ограничивает сложные задачи, такие как seq2seq.\n","\n","По умолчанию все keras RNN применяются ко всей последовательности входных данных и создают последовательность скрытых состояний `(return_sequences = True` или только последнее скрытое состояние` (return_sequences = False) `. Все повторения происходят под капотом.\n","\n","В верхней части нашей модели нам нужно применить плотный слой к каждому временному шагу независимо. На данный момент по умолчанию keras.layers.Dense будет применяться один раз ко всем объединенным временным шагам. Мы используем __keras.layers.TimeDistributed__ для изменения слоя Dense, чтобы он применялся как для пакетной, так и для временной осей."]},{"cell_type":"code","metadata":{"id":"OQeb8d5j8aHv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621104382363,"user_tz":-420,"elapsed":942,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"c2ca7fa8-0c58-4cb8-993d-a3b22498e4c2"},"source":["import keras\n","import keras.layers as L\n","\n","model = keras.models.Sequential()\n","model.add(L.InputLayer([None],dtype='int32'))\n","model.add(L.Embedding(len(all_words),50))\n","model.add(L.SimpleRNN(64,return_sequences=True))\n","\n","#add top layer that predicts tag probabilities\n","stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n","stepwise_dense = L.TimeDistributed(stepwise_dense)\n","model.add(stepwise_dense)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obRVUqOrx5ff","executionInfo":{"status":"ok","timestamp":1621094816720,"user_tz":-420,"elapsed":979,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"c7e311d4-e4b7-4266-d2e8-7ec9dc83eeaf"},"source":["model.summary()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, None, 50)          500100    \n","_________________________________________________________________\n","simple_rnn_1 (SimpleRNN)     (None, None, 64)          7360      \n","_________________________________________________________________\n","time_distributed_1 (TimeDist (None, None, 14)          910       \n","=================================================================\n","Total params: 508,370\n","Trainable params: 508,370\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lQbJqM2n8aHv"},"source":["__Training:__ in this case we don't want to prepare the whole training dataset in advance. The main cause is that the length of every batch depends on the maximum sentence length within the batch. This leaves us two options: use custom training code as in previous seminar or use generators.\n","\n","Keras models have a __`model.fit_generator`__ method that accepts a python generator yielding one batch at a time. But first we need to implement such generator:"]},{"cell_type":"markdown","metadata":{"id":"4onDovJFyawY"},"source":["__Training: __ в этом случае мы не хотим заранее готовить весь набор обучающих данных. Основная причина заключается в том, что длина каждого пакета зависит от максимальной длины предложения в пакете. Это оставляет нам два варианта: использовать специальный обучающий код, как на предыдущем семинаре, или использовать генераторы.\n","\n","В моделях Keras есть метод __`model.fit_generator`__, который принимает генератор Python, выдающий по одной партии за раз. Но для начала нам нужно реализовать такой генератор:"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"kpeMsDi18aHw","executionInfo":{"status":"ok","timestamp":1621104389120,"user_tz":-420,"elapsed":984,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["from keras.utils.np_utils import to_categorical\n","BATCH_SIZE=32\n","def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n","    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n","    \n","    while True:\n","        indices = np.random.permutation(np.arange(len(sentences)))\n","        for start in range(0,len(indices)-1,batch_size):\n","            batch_indices = indices[start:start+batch_size]\n","            batch_words,batch_tags = [],[]\n","            for sent in sentences[batch_indices]:\n","                words,tags = zip(*sent)\n","                batch_words.append(words)\n","                batch_tags.append(tags)\n","\n","            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n","            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n","\n","            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n","            yield batch_words,batch_tags_1hot\n","        "],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zYoR9vgn8aHw"},"source":["__Callbacks:__ Another thing we need is to measure model performance. The tricky part is not to count accuracy after sentence ends (on padding) and making sure we count all the validation data exactly once.\n","\n","While it isn't impossible to persuade Keras to do all of that, we may as well write our own callback that does that.\n","Keras callbacks allow you to write a custom code to be ran once every epoch or every minibatch. We'll define one via LambdaCallback"]},{"cell_type":"markdown","metadata":{"id":"SQecOx3mz0AZ"},"source":["__ Обратные вызовы: __ Еще нам нужно измерить производительность модели. Сложность состоит в том, чтобы не подсчитывать точность после окончания предложения (при заполнении) и не просчитывать все проверочные данные ровно один раз.\n","\n","Хотя убедить Кераса сделать все это не невозможно, мы также можем написать собственный обратный вызов, который сделает это.\n","Обратные вызовы Keras позволяют вам написать собственный код, который будет запускаться один раз в каждую эпоху или каждый мини-пакет. Мы определим один через LambdaCallback"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"CC8woNtV8aHx","executionInfo":{"status":"ok","timestamp":1621104394948,"user_tz":-420,"elapsed":922,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["def compute_test_accuracy(model):\n","    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n","    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n","\n","    #predict tag probabilities of shape [batch,time,n_tags]\n","    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n","    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n","\n","    #compute accurary excluding padding\n","    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n","    denominator = np.sum(test_words != 0)\n","    return float(numerator)/denominator\n","\n","\n","class EvaluateAccuracy(keras.callbacks.Callback):\n","    def on_epoch_end(self,epoch,logs=None):\n","        sys.stdout.flush()\n","        print(\"\\nMeasuring validation accuracy...\")\n","        acc = compute_test_accuracy(self.model)\n","        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n","        sys.stdout.flush()\n","        "],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"5eJGEWu58aHx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621095866408,"user_tz":-420,"elapsed":227699,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"7717175b-1758-4d63-f267-71c088e2ece5"},"source":["model.compile('adam','categorical_crossentropy')\n","\n","model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n","                    callbacks=[EvaluateAccuracy()], epochs=5,)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/5\n","1344/1343 [==============================] - 39s 29ms/step - loss: 0.2732\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 6s 412us/step\n","\n","Validation accuracy: 0.94089\n","\n","Epoch 2/5\n","1344/1343 [==============================] - 37s 27ms/step - loss: 0.0585\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 6s 416us/step\n","\n","Validation accuracy: 0.94463\n","\n","Epoch 3/5\n","1344/1343 [==============================] - 37s 27ms/step - loss: 0.0519\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 6s 410us/step\n","\n","Validation accuracy: 0.94474\n","\n","Epoch 4/5\n","1344/1343 [==============================] - 36s 26ms/step - loss: 0.0477\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 6s 403us/step\n","\n","Validation accuracy: 0.94541\n","\n","Epoch 5/5\n","1344/1343 [==============================] - 36s 27ms/step - loss: 0.0436\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 6s 430us/step\n","\n","Validation accuracy: 0.94527\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f790b479750>"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"TTN7C34V8aHy"},"source":["Measure final accuracy on the whole test set."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"tHgxnYB68aHy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621095963328,"user_tz":-420,"elapsed":8072,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"6f6e6436-e272-427b-c48a-72b9d8a3fdd9"},"source":["acc = compute_test_accuracy(model)\n","print(\"Final accuracy: %.5f\"%acc)\n","\n","assert acc>0.94, \"Keras has gone on a rampage again, please contact course staff.\""],"execution_count":34,"outputs":[{"output_type":"stream","text":["14335/14335 [==============================] - 6s 440us/step\n","Final accuracy: 0.94527\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5L5Prr4I8aHy"},"source":["### Going bidirectional\n","\n","Since we're analyzing a full sequence, it's legal for us to look into future data.\n","\n","A simple way to achieve that is to go both directions at once, making a __bidirectional RNN__.\n","\n","In Keras you can achieve that both manually (using two LSTMs and Concatenate) and by using __`keras.layers.Bidirectional`__. \n","\n","This one works just as `TimeDistributed` we saw before: you wrap it around a recurrent layer (SimpleRNN now and LSTM/GRU later) and it actually creates two layers under the hood.\n","\n","Your first task is to use such a layer our POS-tagger."]},{"cell_type":"markdown","metadata":{"id":"-zQ3-BBo2jqw"},"source":["### Двунаправленный\n","\n","Поскольку мы анализируем полную последовательность, нам разрешено заглядывать в будущие данные.\n","\n","Простой способ добиться этого - пойти в обоих направлениях одновременно, создав __bidirectional RNN__.\n","\n","В Keras вы можете добиться этого как вручную (используя два LSTM и Concatenate), так и используя __`keras.layers.Bidirectional`__.\n","\n","Он работает так же, как TimeDistributed, который мы видели раньше: вы обертываете его вокруг повторяющегося слоя (SimpleRNN сейчас и LSTM / GRU позже), и он фактически создает два слоя под капотом.\n","\n","Ваша первая задача - использовать такой слой в нашем POS-tagger."]},{"cell_type":"markdown","metadata":{"id":"Tqv5vmEde9Eu"},"source":["***\n","\n","> Решение\n","\n","---\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"tHq0HlTv9DsS","executionInfo":{"status":"ok","timestamp":1621097730896,"user_tz":-420,"elapsed":951,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["del model"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"xWfCrbh-8aHy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621097733490,"user_tz":-420,"elapsed":994,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"77c4e253-1980-4fbb-9e7b-89335fc7fa24"},"source":["#Define a model that utilizes bidirectional SimpleRNN\n","model = keras.models.Sequential()\n","\n","model.add(L.InputLayer([None],dtype='int32'))\n","model.add(L.Embedding(len(all_words),50))\n","model.add(L.Bidirectional(L.SimpleRNN(64, return_sequences=True)))\n","\n","#add top layer that predicts tag probabilities\n","stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n","stepwise_dense = L.TimeDistributed(stepwise_dense)\n","model.add(stepwise_dense)\n","\n","model.summary()"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, None, 50)          500100    \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, None, 128)         14720     \n","_________________________________________________________________\n","time_distributed_3 (TimeDist (None, None, 14)          1806      \n","=================================================================\n","Total params: 516,626\n","Trainable params: 516,626\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Ort64W348aHz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621098132315,"user_tz":-420,"elapsed":393223,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"51388ee9-9c05-42f2-e6f9-6ec7a25c3baf"},"source":["model.compile('adam','categorical_crossentropy')\n","\n","model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n","                    callbacks=[EvaluateAccuracy()], epochs=5,)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1344/1343 [==============================] - 66s 49ms/step - loss: 0.1928\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 11s 780us/step\n","\n","Validation accuracy: 0.95636\n","\n","Epoch 2/5\n","1344/1343 [==============================] - 66s 49ms/step - loss: 0.0426\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 11s 774us/step\n","\n","Validation accuracy: 0.96034\n","\n","Epoch 3/5\n","1344/1343 [==============================] - 67s 50ms/step - loss: 0.0352\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 11s 768us/step\n","\n","Validation accuracy: 0.96213\n","\n","Epoch 4/5\n","1344/1343 [==============================] - 66s 49ms/step - loss: 0.0302\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 11s 761us/step\n","\n","Validation accuracy: 0.96266\n","\n","Epoch 5/5\n","1344/1343 [==============================] - 66s 49ms/step - loss: 0.0256\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 11s 766us/step\n","\n","Validation accuracy: 0.96234\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f78a7ce9b90>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"iWHSkF648aHz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621098163692,"user_tz":-420,"elapsed":12543,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"6821c6a0-eb38-436a-c643-31daf183af66"},"source":["acc = compute_test_accuracy(model)\n","print(\"\\nFinal accuracy: %.5f\"%acc)\n","\n","assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n","print(\"Well done!\")"],"execution_count":39,"outputs":[{"output_type":"stream","text":["14335/14335 [==============================] - 11s 753us/step\n","\n","Final accuracy: 0.96234\n","Well done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DM3K7pQv_Vi9"},"source":["**Вывод:**\n","Использование bidirectional RNN значительно улучшило результат работы нейросети."]},{"cell_type":"markdown","metadata":{"id":"VW_nFppS8aH0"},"source":["Task I: Structured loss functions (more bonus points)\n","\n","Since we're tagging the whole sequence at once, we might as well train our network to do so. Remember linear CRF from the lecture? You can also use it as a loss function for your RNN\n","\n","\n","  * There's more than one way to do so, but we'd recommend starting with [Conditional Random Fields](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)\n","  * You can plug CRF as a loss function and still train by backprop. There's even some neat tensorflow [implementation](https://www.tensorflow.org/api_guides/python/contrib.crf) for you.\n","  * Alternatively, you can condition your model on previous tags (make it autoregressive) and perform __beam search__ over that model."]},{"cell_type":"markdown","metadata":{"id":"RMxCJRTw4q5X"},"source":["Задача I: Структурированные функции потерь (больше бонусных баллов)\n","\n","Поскольку мы маркируем сразу всю последовательность, мы могли бы также обучить нашу сеть этому. Помните линейный CRF из лекции? Вы также можете использовать его как функцию потерь для своей RNN.\n","\n","\n","  * Есть несколько способов сделать это, но мы рекомендуем начать с [Условные случайные поля] (http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)\n","  * Вы можете подключить CRF как функцию потерь и по-прежнему тренироваться по обратному каналу. Есть даже интересная [реализация] тензорного потока (https://www.tensorflow.org/api_guides/python/contrib.crf) для вас.\n","  * В качестве альтернативы вы можете обусловить свою модель предыдущими тегами (сделать ее авторегрессивной) и выполнить поиск __beam__ по этой модели."]},{"cell_type":"code","metadata":{"id":"uXEj1Nm98aH0"},"source":["<YOUR CODE>"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AG_wuMVf8aH0"},"source":["\n","#### Some tips\n","Here there are a few more tips on how to improve training that are a bit trickier to impliment. We strongly suggest that you try them _after_ you've got a good initial model.\n","* __Use pre-trained embeddings__: you can use pre-trained weights from [there](http://ahogrammer.com/2017/01/20/the-list-of-pretrained-word-embeddings/) to kickstart your Embedding layer.\n","  * Embedding layer has a matrix W (layer.W) which contains word embeddings for each word in the dictionary. You can just overwrite them with tf.assign.\n","  * When using pre-trained embeddings, pay attention to the fact that model's dictionary is different from your own.\n","  * You may want to switch trainable=False for embedding layer in first few epochs as in regular fine-tuning.  \n","* __Go beyond SimpleRNN__: there's `keras.layers.LSTM` and `keras.layers.GRU`\n","  * If you want to use a custom recurrent Cell, read [this](https://keras.io/layers/recurrent/#rnn)\n","  * You can also use 1D Convolutions (`keras.layers.Conv1D`). They are often as good as recurrent layers but with less overfitting.\n","* __Stack more layers__: if there is a common motif to this course it's about stacking layers\n","  * You can just add recurrent and 1dconv layers on top of one another and keras will understand it\n","  * Just remember that bigger networks may need more epochs to train\n","* __Regularization__: you can apply dropouts as usual but also in an RNN-specific way\n","  * `keras.layers.Dropout` works inbetween RNN layers\n","  * Recurrent layers also have `recurrent_dropout` parameter\n","* __Gradient clipping__: If your training isn't as stable as you'd like, set `clipnorm` in your optimizer.\n","  * Which is to say, it's a good idea to watch over your loss curve at each minibatch. Try tensorboard callback or something similar.\n","* __Word Dropout__: tl;dr randomly replace words with UNK during training. \n","  * This can also simulate increased amount of unknown words in the test set\n","* __Larger vocabulary__: You can obtain greater performance by expanding your model's input dictionary from 5000 to up to every single word!\n","  * Just make sure your model doesn't overfit due to so many parameters.\n","  * Combined with regularizers or pre-trained word-vectors this could be really good cuz right now our model is blind to >5% of words.  \n","* __More efficient batching__: right now TF spends a lot of time iterating over \"0\"s\n","  * This happens because batch is always padded to the length of a longest sentence\n","  * You can speed things up by pre-generating batches of similar lengths and feeding it with randomly chosen pre-generated batch.\n","  * This technically breaks the i.i.d. assumption, but it works unless you come up with some insane rnn architectures.\n","* __The most important advice__: don't cram in everything at once!\n","  * If you stuff in a lot of modiffications, some of them almost inevitably gonna be detrimental and you'll never know which of them are.\n","  * Try to instead go in small iterations and record experiment results to guide further search.\n","    \n","Good hunting!"]},{"cell_type":"markdown","metadata":{"id":"emx3lRKVFvDI"},"source":["***\n","\n","> Решение\n","\n","---\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"52zVZervF31n"},"source":["Попробую улучшить модель, применяя те или иные приёмы, после каждого оценивая точность модели.—"]},{"cell_type":"markdown","metadata":{"id":"aR6N3N8VHyPp"},"source":["**1. Предварительно обученные Embeddings**"]},{"cell_type":"code","metadata":{"id":"mgUBdjtGSC1b"},"source":["import os\n","import gzip\n","import shutil\n","!wget \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n","with gzip.open('GoogleNews-vectors-negative300.bin.gz', 'rb') as f_in:\n","  with open('GoogleNews-vectors-negative300.bin', 'wb') as f_out:\n","    shutil.copyfileobj(f_in, f_out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNcnDQawH86K","executionInfo":{"status":"ok","timestamp":1621104270781,"user_tz":-420,"elapsed":77501,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["from gensim.models import KeyedVectors\n","word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JLmJ5zoIamwo"},"source":["Так как размер Эмбеддинга word2vec - 300, имеет смысл пересчитать последнюю модель, выставив такой же размер вместо прошлого равного 50, чтобы оценить, какое влияние окажет на модель использование предобученного вектора весов из word2vec."]},{"cell_type":"code","metadata":{"id":"KIDKSb4YDFTy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621105404140,"user_tz":-420,"elapsed":435242,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"b6bdfb34-c207-43e0-e5be-6594041ddd31"},"source":["model = keras.models.Sequential()\n","model.add(L.InputLayer([None],dtype='int32'))\n","model.add(L.Embedding(len(all_words),300))\n","model.add(L.Bidirectional(L.SimpleRNN(64, return_sequences=True)))\n","model.add(L.TimeDistributed(L.Dense(len(all_tags),activation='softmax')))\n","\n","model.compile('adam','categorical_crossentropy')\n","model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n","                    callbacks=[EvaluateAccuracy()], epochs=5,)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1344/1343 [==============================] - 72s 53ms/step - loss: 0.1188\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 14s 1ms/step\n","\n","Validation accuracy: 0.95984\n","\n","Epoch 2/5\n","1344/1343 [==============================] - 71s 53ms/step - loss: 0.0366\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 14s 1ms/step\n","\n","Validation accuracy: 0.96318\n","\n","Epoch 3/5\n","1344/1343 [==============================] - 72s 54ms/step - loss: 0.0280\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 14s 1ms/step\n","\n","Validation accuracy: 0.96399\n","\n","Epoch 4/5\n","1344/1343 [==============================] - 71s 53ms/step - loss: 0.0212\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 14s 1ms/step\n","\n","Validation accuracy: 0.96217\n","\n","Epoch 5/5\n","1344/1343 [==============================] - 71s 53ms/step - loss: 0.0152\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 14s 1ms/step\n","\n","Validation accuracy: 0.96076\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7fce953ad9d0>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"C0gGjAwibSrg"},"source":["Вывод:\n","Можно заметить, что обучение с Embedding_size = 300 поначалу велось с большей точностью, чем в предыдущей модели, где размер эмбеддинга был 50, однако после 5 эпох итоговая точность оказалась ниже.\n","\n","Воспользуемся предобученными данными и загрузим в нашу модель веса предобученных данных, и посмотрим улучшится ли модель.—"]},{"cell_type":"code","metadata":{"id":"-gCFYwxXcCdF","executionInfo":{"status":"ok","timestamp":1621105888590,"user_tz":-420,"elapsed":996,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["embedding_weights = np.zeros((len(all_words), 300))\n","\n","for index,word in enumerate(all_words):\n","    try:\n","        embedding_weights[index, :] = word2vec[word]\n","    except KeyError:\n","        pass"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnHeQr2Ag5ti"},"source":["Строим модель с учетом предобученных весов"]},{"cell_type":"code","metadata":{"id":"prPGiXYvh83D","executionInfo":{"status":"ok","timestamp":1621107402127,"user_tz":-420,"elapsed":960,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["del model"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOtcQ2AxhAzs","executionInfo":{"status":"ok","timestamp":1621107849965,"user_tz":-420,"elapsed":437195,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"39b6965f-6ce0-428b-90ac-0a10cd7b5e21"},"source":["model = keras.models.Sequential()\n","model.add(L.InputLayer([None],dtype='int32'))\n","model.add(L.Embedding(input_dim = len(all_words),\n","                      output_dim = 300,\n","                      weights = [embedding_weights],\n","                      trainable = True))\n","model.add(L.Bidirectional(L.SimpleRNN(64, return_sequences=True)))\n","model.add(L.TimeDistributed(L.Dense(len(all_tags),activation='softmax')))\n","\n","model.compile('adam','categorical_crossentropy')\n","model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n","                    callbacks=[EvaluateAccuracy()], epochs=5,)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1344/1343 [==============================] - 73s 54ms/step - loss: 0.0998\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 15s 1ms/step\n","\n","Validation accuracy: 0.96177\n","\n","Epoch 2/5\n","1344/1343 [==============================] - 72s 53ms/step - loss: 0.0351\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 14s 1ms/step\n","\n","Validation accuracy: 0.96474\n","\n","Epoch 3/5\n","1344/1343 [==============================] - 71s 53ms/step - loss: 0.0280\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 14s 998us/step\n","\n","Validation accuracy: 0.96520\n","\n","Epoch 4/5\n","1344/1343 [==============================] - 72s 54ms/step - loss: 0.0219\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 14s 1ms/step\n","\n","Validation accuracy: 0.96444\n","\n","Epoch 5/5\n","1344/1343 [==============================] - 70s 52ms/step - loss: 0.0168\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 14s 998us/step\n","\n","Validation accuracy: 0.96360\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7fce94c4c6d0>"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"_BqOCeHhj6Q3"},"source":["**Вывод:**\n","Ожидания подтвердились: точность модели действительно улучшилась при использовании предобученных эмбеддингов."]},{"cell_type":"markdown","metadata":{"id":"pdH8nazekKD3"},"source":["**2. Теперь вместо SimpleRNN воспользуемся слоем LSTM и посмотрим, улучшится ли точность.—**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Jt7pinbn5uX","executionInfo":{"status":"ok","timestamp":1621114638584,"user_tz":-420,"elapsed":1500189,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"0d5ba8fd-a839-4f77-95fb-f71861378577"},"source":["model = keras.models.Sequential()\n","model.add(L.InputLayer([None],dtype='int32'))\n","model.add(L.Embedding(input_dim = len(all_words),\n","                      output_dim = 300,\n","                      weights = [embedding_weights],\n","                      trainable = True))\n","model.add(L.Bidirectional(L.LSTM(64, return_sequences=True)))\n","model.add(L.TimeDistributed(L.Dense(len(all_tags),activation='softmax')))\n","\n","model.compile('adam','categorical_crossentropy')\n","model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n","                    callbacks=[EvaluateAccuracy()], epochs=10,)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1344/1343 [==============================] - 125s 93ms/step - loss: 0.1252\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96223\n","\n","Epoch 2/10\n","1344/1343 [==============================] - 122s 91ms/step - loss: 0.0354\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96668\n","\n","Epoch 3/10\n","1344/1343 [==============================] - 122s 91ms/step - loss: 0.0287\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96794\n","\n","Epoch 4/10\n","1344/1343 [==============================] - 122s 91ms/step - loss: 0.0237\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96767\n","\n","Epoch 5/10\n","1344/1343 [==============================] - 122s 91ms/step - loss: 0.0195\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96687\n","\n","Epoch 6/10\n","1344/1343 [==============================] - 122s 91ms/step - loss: 0.0154\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96490\n","\n","Epoch 7/10\n","1344/1343 [==============================] - 122s 91ms/step - loss: 0.0121\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96512\n","\n","Epoch 8/10\n","1344/1343 [==============================] - 122s 91ms/step - loss: 0.0092\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96476\n","\n","Epoch 9/10\n","1344/1343 [==============================] - 121s 90ms/step - loss: 0.0070\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96328\n","\n","Epoch 10/10\n","1344/1343 [==============================] - 121s 90ms/step - loss: 0.0052\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 27s 2ms/step\n","\n","Validation accuracy: 0.96312\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7fce900d8090>"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"sdyc1gASvpCa"},"source":["После 5-й эпохи значение Validation accuracy: 0.96687, что свидетельствует - использование LSTM еще улучшило точность."]},{"cell_type":"markdown","metadata":{"id":"OnRTsgmdv8HI"},"source":["**3. Последний эксперимент - задействуем Dropout.**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QO-B1MoUwJoo","executionInfo":{"status":"ok","timestamp":1621112913769,"user_tz":-420,"elapsed":1666001,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"75e9c710-1e74-4ad7-a736-6b94f3e030b9"},"source":["model_dout = keras.models.Sequential()\n","model_dout.add(L.InputLayer([None],dtype='int32'))\n","model_dout.add(L.Embedding(input_dim = len(all_words),\n","                      output_dim = 300,\n","                      weights = [embedding_weights],\n","                      trainable = True))\n","model_dout.add(L.Bidirectional(L.LSTM(64, \n","                                 return_sequences=True,\n","                                 dropout=0.2,\n","                                 recurrent_dropout=0.2)))\n","model_dout.add(L.TimeDistributed(L.Dense(len(all_tags),activation='softmax')))\n","\n","model_dout.compile('adam','categorical_crossentropy')\n","model_dout.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n","                    callbacks=[EvaluateAccuracy()], epochs=10,)"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1344/1343 [==============================] - 141s 105ms/step - loss: 0.1351\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 30s 2ms/step\n","\n","Validation accuracy: 0.96056\n","\n","Epoch 2/10\n","1344/1343 [==============================] - 138s 103ms/step - loss: 0.0397\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 29s 2ms/step\n","\n","Validation accuracy: 0.96583\n","\n","Epoch 3/10\n","1344/1343 [==============================] - 139s 104ms/step - loss: 0.0331\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 29s 2ms/step\n","\n","Validation accuracy: 0.96744\n","\n","Epoch 4/10\n","1344/1343 [==============================] - 137s 102ms/step - loss: 0.0289\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 29s 2ms/step\n","\n","Validation accuracy: 0.96802\n","\n","Epoch 5/10\n","1344/1343 [==============================] - 139s 103ms/step - loss: 0.0256\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 29s 2ms/step\n","\n","Validation accuracy: 0.96865\n","\n","Epoch 6/10\n","1344/1343 [==============================] - 139s 103ms/step - loss: 0.0228\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 30s 2ms/step\n","\n","Validation accuracy: 0.96818\n","\n","Epoch 7/10\n","1344/1343 [==============================] - 138s 103ms/step - loss: 0.0203\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 30s 2ms/step\n","\n","Validation accuracy: 0.96832\n","\n","Epoch 8/10\n","1344/1343 [==============================] - 137s 102ms/step - loss: 0.0181\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 29s 2ms/step\n","\n","Validation accuracy: 0.96801\n","\n","Epoch 9/10\n","1344/1343 [==============================] - 127s 95ms/step - loss: 0.0161\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 29s 2ms/step\n","\n","Validation accuracy: 0.96775\n","\n","Epoch 10/10\n","1344/1343 [==============================] - 127s 95ms/step - loss: 0.0143\n","\n","Measuring validation accuracy...\n","14335/14335 [==============================] - 29s 2ms/step\n","\n","Validation accuracy: 0.96726\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7fce9675e150>"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"eZpurAgM3JCM"},"source":["**Вывод:**\n","Совсем замечательная картина после использования Dropout, после 5-й эпохи Validation accuracy: 0.96865."]},{"cell_type":"code","metadata":{"id":"-COJN-ttAQnC","executionInfo":{"status":"ok","timestamp":1621115653974,"user_tz":-420,"elapsed":902,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["model_val=[0.96223, 0.96668, 0.96794, 0.96767, 0.96687, 0.96490, 0.96512, 0.96476, 0.96328, 0.96312]\n","model_dout_val=[0.96056, 0.96583, 0.96744, 0.96802, 0.96865, 0.96818, 0.96832, 0.96801, 0.96775, 0.96726]"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"6wB4V0H_kckt","executionInfo":{"status":"ok","timestamp":1621115671018,"user_tz":-420,"elapsed":1046,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}},"outputId":"35d952b3-1f18-4aee-d450-707935063684"},"source":["from matplotlib import pyplot as plt\n","\n","plt.plot(model_val)\n","plt.plot(model_dout_val)\n","plt.title('model val accuracy')\n","plt.ylabel('val accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['model LSTM', 'model LSTM + Dropout'], loc=\"lower right\")\n","plt.show()"],"execution_count":72,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"A_do6LrE-UMm"},"source":["На графике видно, как Dropout препятствует переобучению. На десяти эпохах модель с LSTM достигает максимума на валидационной выборке на второй эпохе, а затем  - несмотря на то, что на тесте точность постоянно возрастает (смотри логи обучения), точность на валидации довольно резко падает. Это свидетельствует о переобучении модели на train выборке.\n","\n","Тогда как введение Dropout способствует более сбалансированному обучению."]},{"cell_type":"code","metadata":{"id":"D6bKTZj9C3qD","executionInfo":{"status":"ok","timestamp":1621116075543,"user_tz":-420,"elapsed":927,"user":{"displayName":"Ivan Satura","photoUrl":"","userId":"17630606358964468039"}}},"source":["import pickle\n","pickle.dump(embedding_weights, open('emb_weigths.pkl', 'wb'),protocol=4)"],"execution_count":73,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RhiWdaH_5lWK"},"source":["#### Перевод"]},{"cell_type":"markdown","metadata":{"id":"b3agUtzc5Gx1"},"source":["Несколько советов\n","Вот еще несколько советов о том, как улучшить тренировку, которые немного сложнее реализовать. Мы настоятельно рекомендуем вам попробовать их _после__ того, как у вас будет хорошая начальная модель.\n","* __Используйте предварительно обученные вложения __: вы можете использовать предварительно обученные веса из [там] (http://ahogrammer.com/2017/01/20/the-list-of-pretrained-word-embeddings/), чтобы начать встраивание слой.\n","  * Встраиваемый слой имеет матрицу W (layer.W), которая содержит вложения слов для каждого слова в словаре. Вы можете просто перезаписать их с помощью tf.assign.\n","  * При использовании предварительно обученных эмбеддингов обратите внимание на то, что словарь модели отличается от вашего собственного.\n","  * Вы можете переключить trainable = False для встраивания слоя в первые несколько эпох, как при обычной тонкой настройке.\n","* __Войдите за пределы SimpleRNN__: есть `keras.layers.LSTM` и` keras.layers.GRU`\n","* Если вы хотите использовать настраиваемую повторяющуюся ячейку, прочтите [это] (https://keras.io/layers/recurrent/#rnn)\n","  * Вы также можете использовать одномерные свертки (`keras.layers.Conv1D`). Часто они не уступают повторяющимся слоям, но с меньшим количеством переобучений.\n","* __Складывайте больше слоев__: если у этого курса есть общий мотив, то он о наложении слоев\n","  * Вы можете просто добавить повторяющиеся слои и слои 1dconv друг на друга, и keras поймет это\n","  * Просто помните, что для более крупных сетей может потребоваться больше эпох для обучения\n","* __Regularization__: отсев можно применять как обычно, но также и специфичным для RNN способом.\n","  * `keras.layers.Dropout` работает между слоями RNN\n","  * Рекуррентные слои также имеют параметр recurrent_dropout\n","* __Gradient clipping__: Если ваше обучение не так стабильно, как хотелось бы, установите clipnorm в оптимизаторе.\n","  * Другими словами, рекомендуется следить за кривой потерь на каждой мини-партии. Попробуйте обратный вызов tenorboard или что-то подобное.\n","* __Word Dropout__: tl; dr случайным образом заменяет слова на UNK во время обучения.\n","  * Это также может имитировать увеличенное количество неизвестных слов в тестовом наборе\n","* __Больше словаря__: вы можете добиться большей производительности, расширив входной словарь вашей модели с 5000 до каждого отдельного слова!\n","  * Просто убедитесь, что ваша модель не переоснащается из-за такого количества параметров.\n","  * В сочетании с регуляризаторами или предварительно обученными векторами слов это может быть действительно хорошо, потому что сейчас наша модель слепа к> 5% слов.\n","* __Более эффективное пакетирование__: сейчас TF тратит много времени на итерацию по \"0\" сек.\n","  * Это происходит потому, что партия всегда дополняется до длины самого длинного предложения.\n","  * Вы можете ускорить процесс, предварительно сгенерировав пакеты одинаковой длины и загрузив их случайно выбранными предварительно созданными пакетами.\n","  * Это технически нарушает i.i.d. предположение, но это работает, если вы не придумаете какие-то безумные архитектуры rnn.\n","* __Самый главный совет__: не впихивайте все сразу!\n","  * Если вы добавите много модификаций, некоторые из них почти неизбежно будут вредными, и вы никогда не узнаете, какие из них.\n","  * Вместо этого попробуйте проводить небольшие итерации и записывать результаты экспериментов, чтобы направлять дальнейший поиск."]}]}